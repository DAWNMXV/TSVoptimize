import pandas as pd
import sys
import os
import shutil
import traceback
from tqdm import tqdm
import config as cfg
import run_simulation
import brun_data
import logging
from ansys.aedt.core import settings

# ---------------------------
# æ—¥å¿—è®¾ç½® (ä¿æŒåŸæ ·)
settings.enable_screen_logs = False
settings.enable_file_logs = False
settings.enable_global_log_file = False
logger = logging.getLogger("ansys.aedt.core")
logger.setLevel(logging.ERROR)
# ---------------------------

# ==========================================
# ğŸ”§ ç”¨æˆ·é…ç½®åŒº
# ==========================================
TARGET_ROWS = list(range(1,10))


# ==========================================

def cleanup_simulation_files(run_index):
    """æ¸…ç† HFSS æ¨¡å‹æ–‡ä»¶"""
    try:
        if os.path.exists(cfg.project_name):
            os.remove(cfg.project_name)
        results_folder = cfg.project_name + "results"
        if os.path.exists(results_folder):
            shutil.rmtree(results_folder)
        lock_file = cfg.project_name + ".lock"
        if os.path.exists(lock_file):
            os.remove(lock_file)
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†æ–‡ä»¶é”™è¯¯: {e}")


def append_to_nn_database(run_index, parameter_set):
    """
    ã€æ–°é€»è¾‘ã€‘
    è¯»å– brun_data ç”Ÿæˆçš„å¤šé¢‘ç‚¹æ±‡æ€» CSVï¼Œ
    å°† LHS å‚æ•°åˆå¹¶åˆ°æ¯ä¸€è¡Œï¼Œç„¶åè¿½åŠ åˆ° Master CSVã€‚
    """
    try:
        # 1. è¯»å– brun_data ç”Ÿæˆçš„ CSV
        if not os.path.exists(cfg.csv_run_summary):
            print(f"âš ï¸ Run {run_index} æœªç”Ÿæˆæ±‡æ€»æ–‡ä»¶ï¼Œè·³è¿‡å…¥åº“ã€‚")
            return

        df_run = pd.read_csv(cfg.csv_run_summary)

        # 2. å°† LHS è¾“å…¥å‚æ•°æ‰“å…¥æ¯ä¸€è¡Œ
        # parameter_set æ˜¯å­—å…¸ { 'via_pitch': 40, ... }
        for param_key, param_val in parameter_set.items():
            df_run[param_key] = param_val

        # æ·»åŠ  run_index
        df_run['run_index'] = run_index

        # 3. è¿½åŠ åˆ°ä¸»è®­ç»ƒåº“
        target_csv = cfg.csv_nn_training_data

        if os.path.exists(target_csv):
            try:
                # è¯»å–æ—§åº“
                existing_df = pd.read_csv(target_csv)

                # å¦‚æœ run_index å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤æ—§çš„ (æ”¯æŒé‡è·‘)
                if 'run_index' in existing_df.columns:
                    rows_before = len(existing_df)
                    existing_df = existing_df[existing_df['run_index'] != run_index]
                    if len(existing_df) < rows_before:
                        print(f"ğŸ”„ [Update] è¦†ç›– Run {run_index} çš„æ—§è®°å½•...")

                # åˆå¹¶
                final_df = pd.concat([existing_df, df_run], ignore_index=True)

                # ç®€å•æ’åº (æŒ‰ Run å†æŒ‰ Freq)
                if 'Frequency_GHz' in final_df.columns:
                    final_df = final_df.sort_values(by=['run_index', 'Frequency_GHz'])

                final_df.to_csv(target_csv, index=False)

            except Exception as e:
                print(f"âš ï¸ è¯»å–ä¸»åº“å¤±è´¥ ({e})ï¼Œå°è¯•ç›´æ¥è¿½åŠ æ¨¡å¼...")
                df_run.to_csv(target_csv, mode='a', header=False, index=False)
        else:
            # ç¬¬ä¸€æ¬¡åˆ›å»º
            df_run.to_csv(target_csv, mode='w', header=True, index=False)

        print(f"âœ… Run {run_index} ({len(df_run)} è¡Œæ•°æ®) å·²æˆåŠŸå…¥åº“ã€‚")

    except Exception as e:
        print(f"âŒ (Run {run_index}) æ•°æ®èšåˆå¤±è´¥: {e}")
        traceback.print_exc()


def run_single_simulation(run_index, parameter_set):
    try:
        print(f"\n{'=' * 25} å¼€å§‹è¿è¡Œç¬¬ {run_index} ç»„ {'=' * 25}")
        cfg.update_params_and_paths(run_index, parameter_set)

        # 1. ä»¿çœŸ
        run_simulation.main()
        # 2. åå¤„ç†
        brun_data.main()
        # 3. å…¥åº“
        append_to_nn_database(run_index, parameter_set)

        return True
    except Exception as e:
        print(f"\n{'!' * 25} ç¬¬ {run_index} ç»„å¤±è´¥ {'!' * 25}")
        traceback.print_exc()
        return False


if __name__ == "__main__":
    lhs_data_file = "lhs_data.csv"

    try:
        lhs_data = pd.read_csv(lhs_data_file)
        print(f"âœ… åŠ è½½ {len(lhs_data)} ç»„å‚æ•°ã€‚")
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½ lhs_data.csv: {e}")
        sys.exit(1)

    if TARGET_ROWS:
        rows_to_process = [(r, lhs_data.iloc[r - 1]) for r in TARGET_ROWS if 1 <= r <= len(lhs_data)]
    else:
        rows_to_process = [(i + 1, row) for i, row in lhs_data.iterrows()]

    print(f"ğŸš€ è®¡åˆ’æ‰§è¡Œ {len(rows_to_process)} ä¸ªä»»åŠ¡...")

    pbar = tqdm(rows_to_process, desc="LHS è¿›åº¦", unit="ç»„")

    # è®°å½•ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªéœ€è¦å¤„ç†çš„IDï¼Œç”¨äºä¿ç•™æ¨¡å‹
    if len(rows_to_process) > 0:
        first_run_id = rows_to_process[0][0]
        last_run_id = rows_to_process[-1][0]
    else:
        first_run_id = -1
        last_run_id = -1

    for run_index, row_series in pbar:
        parameter_set = row_series.to_dict()
        pbar.set_description(f"LHS Run {run_index}")

        if run_single_simulation(run_index, parameter_set):
            # ç£ç›˜ä¼˜åŒ–: åªä¿ç•™åˆ—è¡¨ä¸­çš„é¦–å°¾
            if run_index != first_run_id and run_index != last_run_id:
                cleanup_simulation_files(run_index)
            else:
                print(f"ğŸ’¾ ä¿ç•™æ¨¡å‹æ–‡ä»¶ (Run {run_index})")

    print("\nğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆ ğŸ‰")